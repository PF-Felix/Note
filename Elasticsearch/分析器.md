# 常见的中文分析器

```shell
GET custom_analysis/_analyze
{
  "analyzer": "ik_max_word",
  "text": [
    "我爱中华人民共和国"
  ]
}

GET custom_analysis/_analyze
{
  "analyzer": "ik_max_word",
  "text": [
    "蒙丢丢",
    "大G",
    "霸道",
    "渣男",
    "渣女",
    "奥巴马"
  ]
}

GET custom_analysis/_analyze
{
  "analyzer": "ik_max_word",
  "text": [
    "吴磊",
    "美国",
    "日本",
    "澳大利亚"
  ]
}
```

ES 还可以自定义分析器，自定义分析器包含过滤器

# 过滤器

> filter

过滤器用于分词之前预处理，过滤无用字符
可以做到：大小写转换、词项转换、语气词处理

```shell
#《html_strip》
DELETE my_index
PUT my_index
{
  "settings": {
    "analysis": {
      "char_filter": {
        "my_char_filter": {
          "type": "html_strip",
          "escaped_tags": ["a"]
        }
      },
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "char_filter": ["my_char_filter"]
        }
      }
    }
  }
}
GET my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "<p>I&apos;m so <a>happy</a>!</p>"
}

#《mapping》
DELETE my_index
PUT my_index
{
  "settings": {
    "analysis": {
      "char_filter": {
        "my_char_filter": {
          "type": "mapping",
          "mappings": [
            "滚 => *",
            "垃 => *",
            "圾 => *"
          ]
        }
      },
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "char_filter": [
            "my_char_filter"
          ]
        }
      }
    }
  }
}
GET my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "你就是个垃圾！滚"
}

#《pattern replace》
DELETE my_index
PUT my_index
{
  "settings": {
    "analysis": {
      "char_filter": {
        "my_char_filter": {
          "type": "pattern_replace",
          "pattern": """(\d{3})\d{4}(\d{4})""",
          "replacement": "$1****$2"
        }
      },
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "char_filter": ["my_char_filter"]
        }
      }
    }
  }
}
GET my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "您的手机号是17611001200"
}

#《synonym同义词替代》
DELETE test_index
PUT /test_index
{
  "settings": {
    "analysis": {
      "filter": {
        "my_synonym": {
          "type": "synonym",
          "synonyms": [
            "赵,钱,孙,李=>吴",
            "周=>王"
          ]
        }
      },
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "filter": [
            "my_synonym"
          ]
        }
      }
    }
  }
}
GET test_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": [
    "赵,钱,孙,李",
    "周"
  ]
}
```

# 分词器

> tokenizer

常见分词器：
standard：默认分词器，中文支持的不理想，会逐字拆分
pattern：以正则匹配分隔符，把文本拆分成若干词项
whitespace：以空白符分隔

自定义分词器：

```shell
DELETE custom_analysis
PUT custom_analysis
{
  "settings": {
    "analysis": {
      "char_filter": {
        "my_char_filter": {
          "type": "mapping",
          "mappings": [
            "& => and",
            "| => or"
          ]
        },
        "html_strip_char_filter": {
          "type": "html_strip",
          "escaped_tags": [
            "a"
          ]
        }
      },
      "filter": {
        "my_stopword": {
          "type": "stop",
          "stopwords": [
            "is",
            "in",
            "the",
            "a",
            "at",
            "for"
          ]
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "pattern",
          "pattern": "[ ,.!?]"
        }
      },
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "char_filter": [
            "my_char_filter",
            "html_strip_char_filter"
          ],
          "filter": [
            "my_stopword",
            "lowercase"
          ],
          "tokenizer": "my_tokenizer"
        }
      }
    }
  }
}
GET custom_analysis/_analyze
{
  "analyzer": "my_analyzer",
  "text": [
    "What is ,<a>as.df</a>  ss<span> in ? &</span> | is ! in the a at for "
  ]
}
```
